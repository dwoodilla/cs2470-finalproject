{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d65c520a",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "This notebook is intended to process data in the \"downloaded\" folder into tensorized form, particularly aqs and meteorology data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5897db02",
   "metadata": {},
   "source": [
    "## 1. Join AQ and Met datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "bd9e1f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "PARAM_DICT = {\n",
    "    \"44201\": \"o3\",\n",
    "    \"68105\": \"avg_temp\",\n",
    "    \"62101\": \"outdoor_temp\",\n",
    "    \"61301\": \"mix_height\",\n",
    "    \"42101\": \"co\",\n",
    "    \"42601\": \"no\",\n",
    "    \"42602\": \"no2\",\n",
    "    \"88101\": \"pm25\",\n",
    "    \"86101\": \"pm10_25\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "dabd6fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list:list[pd.DataFrame] = []\n",
    "\n",
    "for dataset in os.listdir(\"./data/downloaded/aqs/\"):\n",
    "    if \"json\" not in dataset: continue\n",
    "    with open(os.path.join(\"./data/downloaded/aqs/\", dataset)) as f:\n",
    "        raw_json = json.load(f)\n",
    "    df = pd.json_normalize(raw_json['Data'])\n",
    "    df['datetime_gmt'] = pd.to_datetime(df['date_gmt'] + ' ' + df['time_gmt'], utc=True)\n",
    "\n",
    "    df = df[['datetime_gmt','parameter_code','sample_measurement']]\n",
    "    df['parameter_code'] = df['parameter_code'].apply(lambda x: PARAM_DICT[x])\n",
    "    df = df.pivot_table(\n",
    "        index='datetime_gmt',\n",
    "        columns='parameter_code',\n",
    "        values='sample_measurement',\n",
    "        dropna=False\n",
    "    ).reset_index()\n",
    "    df = df.drop(columns=['avg_temp','mix_height', 'pm10_25'], errors='ignore')\n",
    "    df_list.extend([df])\n",
    "\n",
    "aq_ds_primary = pd.concat(df_list)\n",
    "aq_ds_primary['datetime_gmt'] = pd.to_datetime(aq_ds_primary['datetime_gmt'], utc=True, errors='raise')\n",
    "aq_ds_primary = aq_ds_primary.set_index('datetime_gmt')\n",
    "aq_ds_primary.to_pickle('./data/downloaded/myron_ds.pkl')\n",
    "aq_ds_primary.to_json('./data/downloaded/myron_ds.json', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "cf41f842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ■■■                                8% |  ETA: 29s\n",
      " ■■■■■■                            17% |  ETA: 26s\n",
      " ■■■■■■■■■                         25% |  ETA: 24s\n",
      " ■■■■■■■■■■■                       33% |  ETA: 21s\n",
      " ■■■■■■■■■■■■■                     42% |  ETA: 19s\n",
      " ■■■■■■■■■■■■■■■■                  50% |  ETA: 16s\n",
      " ■■■■■■■■■■■■■■■■■■■               58% |  ETA: 13s\n",
      " ■■■■■■■■■■■■■■■■■■■■■             67% |  ETA: 11s\n",
      " ■■■■■■■■■■■■■■■■■■■■■■■           75% |  ETA:  8s\n",
      " ■■■■■■■■■■■■■■■■■■■■■■■■■■        83% |  ETA:  5s\n",
      " ■■■■■■■■■■■■■■■■■■■■■■■■■■■■■     92% |  ETA:  3s\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects as ro\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "\n",
    "worldmet = importr(\"worldmet\")\n",
    "\n",
    "ro.r('''\n",
    "\t# met_ds = worldmet::importNOAA(code=c(\"997278-99999\",\"725070-14765\"), year=2014:2025)\n",
    "\tmet_ds = worldmet::importNOAA(code=c(\"725070-14765\"), year=2014:2025)\n",
    "''')\n",
    "\n",
    "met_ds_primary:pd.DataFrame\n",
    "with (ro.default_converter + pandas2ri.converter).context():\n",
    "    met_ds_primary = ro.r['met_ds'] # type: ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7c0f06a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "met_ds = met_ds_primary\n",
    "aq_ds  = aq_ds_primary\n",
    "met_ds = met_ds.rename(columns={\"date\":\"datetime\"})\n",
    "met_ds = met_ds.reset_index()\n",
    "aq_ds  = aq_ds.reset_index()\n",
    "aq_ds  = aq_ds .rename(columns={\"datetime_gmt\":\"datetime\"})\n",
    "\n",
    "met_ds = met_ds.drop(\n",
    "    columns=[\n",
    "        'cl_2','cl_3','cl_2_height','cl_3_height','precip_6','pwc',\n",
    "\t\t'code','station','latitude','longitude','elev'\n",
    "\t]\n",
    ")\n",
    "met_ds = met_ds.rename(\n",
    "    columns={\n",
    "        \"Uu\":\"ws_east_west\",\n",
    "        \"Vv\":\"ws_north_south\"\n",
    "\t}\n",
    ")\n",
    "\n",
    "met_ds['datetime'] = pd.to_datetime(met_ds['datetime'], utc=True)\n",
    "aq_ds['datetime']  = pd.to_datetime(aq_ds['datetime'], utc=True)\n",
    "ds = pd.merge_ordered(\n",
    "    met_ds,\n",
    "    aq_ds,\n",
    "    on='datetime'\n",
    ")\n",
    "\n",
    "ds.to_json(\"data/joined_met_aq_ds.json\", indent=2, index=True)\n",
    "ds.to_pickle(\"data/joined_met_aq_ds.pckl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17213f0",
   "metadata": {},
   "source": [
    "## 2. Tensorize joined dataset\n",
    "\n",
    "Convert dataset from pd.DataFrame to tf.Tensor; split and encode datetime information using differentiable function; process missing data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "csci2470",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
